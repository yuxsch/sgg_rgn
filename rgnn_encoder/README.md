
This is the encoder part of our codes for our ICPR 2022 paper.
You can get more information from our ICPR 2022 paper and our supplementaty material pdf file.
You can get big files in our google drive https://drive.google.com/drive/folders/1tYpC70ZMT10vTbrjur1JcD1ftsu2XyE5?usp=sharing
We developed this repository based on an open-source project:  http://github.com/svjan5/kg-reeval.

## Requirements
	Python 3.7.11
    numpy  1.16.2
    PyTorch 1.9.0 (CUDA 11.1) 
	
## Our hardware configuration and CUDA Version

	CPU: Intel(R) Xeon(R) Gold 5222 CPU @ 3.80GHz
	GPU: NVIDIA Corporation TU102 [GeForce RTX 2080 Ti] 
	CUDA Toolkit Version: Release 11.1, V11.1.105

## Overview
The codes is under the folder /code/rgnn_decoder. The encoder aims to generate neighborhood-aware embeddings that capture the semantic correlations between the triples in different images. The encoder includes 2 steps: knowledge graph generation and RGNN training.

## Knowledge graph generation
We have already generated the knowledge graph for you, you can skip this step. But you can still refer our code /code/rgnn_decoder/graph_generation.py. In this step, we extract triples in each image of VG and generate the knowledge graph for RGNN learning, named VG-KB (KB means knowledge base).
Before you run the python file, please make sure the folder /code/rgnn_decoder/data/VG-KB includes the input files VG-SGG-dicts-with-attri.json, train_idx.txt, valid_idx.txt, test_idx.txt (VG dataset) and glove.6B.200d.txt (word embedding). Note that VG-SGG-with-attri.h5 and glove.6B.200d.txt are in the google drive. The output files are our knowledge graph (i.e., VG-KB) and located in /code/rgnn_decoder/data/VG-KB.

    train.txt; valid.txt; test.txt: The training, valid, and test knowledge graph for RGNN learning. Of course, you only need train.txt if you do not need to tune our RGNN model.
    entity2id.txt; relation2id: We transform the entity strings and relation strings to ids.
    entity2vec.txt; relation2vec.txt: We initiate the RGNN embedding using the word embedding. 

## RGNN training
After the knowledge graph is constructed, we start to train our RGNN model. The models are stored in /code/rgnn_decoder/models.py and /code/rgnn_decoder/layers.py. You can simply train our model with a single command:
    
	python main.py --gpu 0

Also, you can change the depth of our RGNN model with the arg: --depth_gat (the default is 3). For example: 
    
	python main.py --gpu 0 --depth_gat 1

After the training, in /code/rgnn_decoder/data/VG-KB/na, you get:
    
	glove.6B.200d.txt: The neighborhood-aware entity embeddings generated by our encoder. Note that it is the same as word embedding filename, so do not confuse them. In our google drive, it is named as entity.6B.200d.txt.
    relation.6B.200d.txt: The neighborhood-aware relation embeddings generated by our encoder.

## Reproduce our results shown in Table 3,4 of our paper
Our encoder learns the neighborhood-aware embeddings of entities and relations, which capture rich information of the knowledge graph, including the similarity between entities and the transitional correlation between the subject, predicate, and object in each triple. You can simply get the cosine similarity rank of entities and the reasonable predicate rank with a single command:
    
	python calc_dis_and_score.py


The output files are located in /code/rgnn_decoder/data/VG-KB/na.
    
	dis.txt: The cosine distance $s_{i,j}$ between the neighborhood-aware embeddings.
    dis_rank.txt: The rank of cosine distance. Table 3 is a subset of it.
    score: The score value $d_{i,r,j}$ of each triple. A small value of $d_{i,k,j}$ represents that the triple $t_{i,k,j} = (e_i,r_k,e_j)$ is true and reasonable. 
    score_rank.txt: The rank of the score value $d_{i,r,j}$. Table 4 is a subset of it.
	
You can also get these files in our google drive.
